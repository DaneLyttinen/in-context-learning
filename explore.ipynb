{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, einsum\n",
    "from einops import rearrange\n",
    "\n",
    "from utils.data import RandomLinearProjectionMNIST, DATA_PATH, get_mnist_data_loaders, get_emnist_data_loaders, select_from_classes\n",
    "from utils.visualization import show_imgs, get_model_dot, LivePlot\n",
    "from utils.others import measure_alloc_mem, count_parameters\n",
    "from utils.timing import func_timer\n",
    "from utils.metrics import get_accuracy\n",
    "\n",
    "import wandb\n",
    "from IPython.display import clear_output\n",
    "import tqdm\n",
    "from livelossplot import PlotLosses\n",
    "import lovely_tensors as lt\n",
    "\n",
    "lt.monkey_patch()\n",
    "torch.set_printoptions(precision=3, linewidth=180)\n",
    "%env \"WANDB_NOTEBOOK_NAME\" \"explore.ipynb\"\n",
    "wandb.login()\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"batch_size\": 24,\n",
    "    \"seq_len\": 100,\n",
    "    \"num_of_tasks\": 2**10,\n",
    "    \"permuted_images_frac\": 1.0,\n",
    "    \"permuted_labels_frac\": 0.3,\n",
    "    \"whole_seq_prediction\": True,\n",
    "    \"lr\": 3e-4,\n",
    "    \"eps\": 1e-16,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "}\n",
    "\n",
    "print(f\"... Running on {config['device']} ...\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_lin_proj_mnist_dataset_train = RandomLinearProjectionMNIST(\n",
    "    orig_mnist_dataset=datasets.MNIST(DATA_PATH, train=True, download=False, transform=RandomLinearProjectionMNIST.get_default_transform()),\n",
    "    num_tasks=config[\"num_of_tasks\"],\n",
    "    seq_len=config[\"seq_len\"],\n",
    "    permuted_images_frac=config[\"permuted_images_frac\"],\n",
    "    permuted_labels_frac=config[\"permuted_labels_frac\"],\n",
    "    labels_shifted_by_one=config[\"whole_seq_prediction\"],\n",
    "    spare_mem=True,\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(rand_lin_proj_mnist_dataset_train, batch_size=config[\"batch_size\"], shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "rand_lin_proj_mnist_dataset_test = RandomLinearProjectionMNIST(\n",
    "    orig_mnist_dataset=datasets.MNIST(DATA_PATH, train=False, download=False, transform=RandomLinearProjectionMNIST.get_default_transform()),\n",
    "    num_tasks=config[\"num_of_tasks\"],\n",
    "    seq_len=config[\"seq_len\"],\n",
    "    permuted_images_frac=0.,\n",
    "    permuted_labels_frac=0.,\n",
    "    labels_shifted_by_one=config[\"whole_seq_prediction\"],\n",
    "    spare_mem=True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(rand_lin_proj_mnist_dataset_test, batch_size=config[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_labels_shifted_by_one(data_loader):\n",
    "    # test that the labels are shifted by one to the right\n",
    "    for x, y in data_loader:\n",
    "        assert x.shape == (config[\"batch_size\"], config[\"seq_len\"], 784 + 10)\n",
    "        assert y.shape == (config[\"batch_size\"], config[\"seq_len\"])\n",
    "        assert torch.all(x[:,0,-10:] == 0)\n",
    "        assert torch.all(x[:,1:,-10:].argmax(-1) == y[:,:-1])\n",
    "        break\n",
    "\n",
    "def test_labels_not_shifted_by_one(data_loader):\n",
    "    # test that the labels are not shifted by one to the right\n",
    "    for x, y in data_loader:\n",
    "        assert x.shape == (config[\"batch_size\"], config[\"seq_len\"], 784 + 10)\n",
    "        assert y.shape == (config[\"batch_size\"],)\n",
    "        assert torch.all(x[:,-1,-10:] == 0)\n",
    "        assert torch.all(x[:,:-1,-10:].max(-1).values == 1.)\n",
    "        break\n",
    "\n",
    "if config[\"whole_seq_prediction\"]:\n",
    "    test_labels_shifted_by_one(data_loader=train_loader)\n",
    "    test_labels_shifted_by_one(data_loader=test_loader)\n",
    "else:\n",
    "    test_labels_not_shifted_by_one(data_loader=train_loader)\n",
    "    test_labels_not_shifted_by_one(data_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dataset_projections(dataset):\n",
    "    def get_pseudo_inverse(A, eps=1e-16):\n",
    "        return torch.inverse(A.T @ A + eps * torch.eye(A.shape[1], device=A.device)) @ A.T\n",
    "    lin_projection = torch.normal(0, 1/784, (784, 784), generator=torch.Generator().manual_seed(dataset.lin_transforms[0]))\n",
    "    lin_projection_inv = get_pseudo_inverse(lin_projection)\n",
    "\n",
    "    orig_img = task = torch.utils.data.Subset(rand_lin_proj_mnist_dataset_train.orig_mnist_dataset, rand_lin_proj_mnist_dataset_train.task_idxs[0])[0][0].view(784)\n",
    "    projected_img_manual = lin_projection @ orig_img\n",
    "    # projected_img_manual = (projected_img_manual - projected_img_manual.mean()) / projected_img_manual.std()\n",
    "    projected_img_manual_inv = lin_projection_inv @ projected_img_manual\n",
    "\n",
    "    projected_img = dataset[0][0][0,:-10]\n",
    "    projected_img_inv = (lin_projection_inv @ projected_img)\n",
    "    projected_img_inv = (projected_img_inv - projected_img_inv.mean()) / projected_img_inv.std()\n",
    "\n",
    "    show_imgs(torch.cat((orig_img.view(784), projected_img_manual, projected_img_manual_inv, projected_img, projected_img_inv), dim=0).view(-1,1,28,28))\n",
    "\n",
    "show_dataset_projections(rand_lin_proj_mnist_dataset_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        heads=2,\n",
    "        dim_head=16,\n",
    "        dropout=0.,\n",
    "        causal=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        self.heads = heads\n",
    "        self.causal = causal\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
    "        self.to_out = nn.Linear(inner_dim, dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        q, k, v = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        q, k, v = map(lambda t: rearrange(t, \"b n (h d) -> b h n d\", h=self.heads), (q, k, v))\n",
    "        sim = einsum(\"b h i d, b h j d -> b h i j\", q, k) * self.scale\n",
    "\n",
    "        if self.causal:\n",
    "            # apply causal mask\n",
    "            mask = torch.ones(size=sim.shape[-2:], device=sim.device).triu_(1).bool()\n",
    "            sim.masked_fill_(mask, float(\"-inf\"))\n",
    "\n",
    "        attn = sim.softmax(dim=-1) # (batch, heads, query, key)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = einsum(\"b h i j, b h j d -> b h i d\", attn, v)\n",
    "        out = rearrange(out, \"b h n d -> b n (h d)\", h=self.heads) # merge heads\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        depth,\n",
    "        heads,\n",
    "        dim_head,\n",
    "        token_dim=784 + 10,\n",
    "        inner_dim=None,\n",
    "        dropout=0.,\n",
    "        causal=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed_proj = nn.Linear(token_dim, dim)\n",
    "        self.layers = nn.ModuleList([])\n",
    "        inner_dim = inner_dim or 4 * dim\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout, causal=causal),\n",
    "                nn.LayerNorm(dim),\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(dim, inner_dim),\n",
    "                    nn.GELU(),\n",
    "                    nn.Linear(inner_dim, dim),\n",
    "                    nn.Dropout(dropout)\n",
    "                ),\n",
    "                nn.LayerNorm(dim)\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed_proj(x)\n",
    "        for attn, ln1, mlp, ln2 in self.layers:\n",
    "            x = x + attn(x)\n",
    "            x = x + mlp(ln1(x))\n",
    "        return x\n",
    "\n",
    "class InContextLearner(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        depth=2,\n",
    "        heads=4,\n",
    "        dim_head=16,\n",
    "        inner_dim=None,\n",
    "        dropout=0.1,\n",
    "        whole_seq_prediction=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        inner_dim = inner_dim or 4 * dim\n",
    "        self.whole_seq_prediction = whole_seq_prediction\n",
    "        self.transformer = Transformer(\n",
    "            dim=dim,\n",
    "            depth=depth,\n",
    "            heads=heads,\n",
    "            dim_head=dim_head,\n",
    "            inner_dim=inner_dim,\n",
    "            dropout=dropout,\n",
    "            causal=whole_seq_prediction,\n",
    "        )\n",
    "        self.final_classifier = nn.Linear(dim, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer(x) # (batch, seq_len, dim)\n",
    "        if self.whole_seq_prediction:\n",
    "            return self.final_classifier(x)\n",
    "        else:\n",
    "            return self.final_classifier(x[:,-1,:])\n",
    "\n",
    "# model_dim = 28 * 28 + 10\n",
    "model_dim = 256\n",
    "model = InContextLearner(\n",
    "    dim=model_dim,\n",
    "    depth=4,\n",
    "    heads=6,\n",
    "    dim_head=32,\n",
    "    inner_dim=4 * model_dim,\n",
    "    dropout=0.1,\n",
    "    whole_seq_prediction=config[\"whole_seq_prediction\"]\n",
    ").to(config[\"device\"])\n",
    "print(model)\n",
    "print(f\"{count_parameters(model)} trainable parameters\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval model\n",
    "def eval(model, test_loader, apply_proj=False):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss, acc, acc_max_improvement_within_seq = 0, 0, 0\n",
    "        acc_over_seq = np.array([0.] * config[\"seq_len\"])\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(config[\"device\"]), y.to(config[\"device\"])\n",
    "\n",
    "            # curr_proj_matrices, curr_label_perms = None, None\n",
    "            # if apply_proj:\n",
    "            #     # randomly sample tasks (one task for each sequence/context)\n",
    "            #     task_idxs = np.random.randint(0, config[\"num_of_tasks\"], size=config[\"batch_size\"])\n",
    "            #     curr_proj_matrices, curr_label_perms = proj_matrices[task_idxs].to(config[\"device\"]), label_perms[task_idxs].to(config[\"device\"])\n",
    "            # x, y = get_context_seqs(x, y, proj_matrices=curr_proj_matrices, label_perms=curr_label_perms,\n",
    "            #     seq_len=config[\"seq_len\"], labels_shifted_by_one=config[\"whole_seq_prediction\"]) # (batch, seq_len, dim)\n",
    "\n",
    "            y_hat = model(x)\n",
    "            if config[\"whole_seq_prediction\"]:\n",
    "                loss += F.cross_entropy(y_hat.view(-1, 10), y.view(-1)).item()\n",
    "                acc_over_seq += (y_hat.argmax(dim=-1) == y).float().mean(dim=0).cpu().numpy() # (seq_len,)\n",
    "                acc_max_improvement_within_seq += \\\n",
    "                    ((y_hat[:,1:,:].argmax(dim=-1) == y[:,1:]).float().max(dim=-1).values \\\n",
    "                    - (y_hat[:,0,:].argmax(dim=-1) == y[:,0]).float()).mean().item()\n",
    "            else:\n",
    "                loss += F.cross_entropy(y_hat, y).item()\n",
    "            acc += (y_hat.argmax(dim=-1) == y).float().mean().item()\n",
    "        loss /= len(test_loader)\n",
    "        acc /= len(test_loader)\n",
    "        acc_over_seq = list(acc_over_seq / len(test_loader))\n",
    "        acc_max_improvement_within_seq /= len(test_loader)\n",
    "        print(f\"loss: {loss:.4f}, acc: {acc:.4f}\")\n",
    "    return loss, acc, acc_over_seq, acc_max_improvement_within_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optim = torch.optim.Adam(model.parameters(), lr=config[\"lr\"], eps=config[\"eps\"])\n",
    "\n",
    "# logging\n",
    "groups = [\"train_loss\", \"train_acc\", \"eval_loss\", \"eval_acc\"]\n",
    "if config[\"whole_seq_prediction\"]:\n",
    "    groups.extend([\"train_acc_over_seq\", \"train_acc_max_improvement_within_seq\", \"eval_acc_over_seq\", \"eval_acc_max_improvement_within_seq\"])\n",
    "live_plot = LivePlot(figsize=(26, 24) if config[\"whole_seq_prediction\"] else (26, 14), use_seaborn=False, groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm.tqdm(range(200)):\n",
    "    model.train()\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(config[\"device\"]), y.to(config[\"device\"])\n",
    "        \n",
    "        y_hat = model(x)\n",
    "        if config[\"whole_seq_prediction\"]:\n",
    "            loss = F.cross_entropy(y_hat.view(-1, 10), y.view(-1))\n",
    "        else:\n",
    "            loss = F.cross_entropy(y_hat, y)\n",
    "        loss.backward()\n",
    "        model_optim.step()\n",
    "        model_optim.zero_grad()\n",
    "\n",
    "        # update the plot\n",
    "        if i % 10 == 9:\n",
    "            if config[\"whole_seq_prediction\"]:\n",
    "                acc_over_seq = (y_hat.argmax(dim=-1) == y).float().mean(dim=0) # (seq_len,)\n",
    "                acc_max_improvement_within_seq = \\\n",
    "                    ((y_hat[:,1:,:].argmax(dim=-1) == y[:,1:]).float().max(dim=-1).values \\\n",
    "                    - (y_hat[:,0,:].argmax(dim=-1) == y[:,0]).float()).mean().item()\n",
    "                live_plot.update({\"train_acc_over_seq\": acc_over_seq.tolist()}, reset=True)\n",
    "                live_plot.update({\"train_acc_max_improvement_within_seq\": acc_max_improvement_within_seq})\n",
    "            live_plot.update({\"train_loss\": loss.item(), \"train_acc\": (y_hat.argmax(dim=-1) == y).float().mean().item()})\n",
    "            live_plot.draw()\n",
    "    #     break\n",
    "    loss, acc, acc_over_seq, acc_max_improvement_within_seq = eval(model, test_loader, apply_proj=False)\n",
    "    live_plot.update({\"eval_loss\": loss, \"eval_acc\": acc})\n",
    "    if config[\"whole_seq_prediction\"]:\n",
    "        live_plot.update({\"eval_acc_max_improvement_within_seq\": acc_max_improvement_within_seq})\n",
    "        live_plot.update({\"eval_acc_over_seq\": acc_over_seq}, reset=True)\n",
    "    live_plot.draw()\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (main, Mar 31 2022, 08:41:55) [GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5692ede66a2eeda96ca4e496ad881a063b66ee8e9ec6003b28974c60439bc6fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
