{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, einsum\n",
    "from einops import rearrange\n",
    "\n",
    "from utils.data import DATA_PATH,get_mnist_data_loaders, get_emnist_data_loaders, randomize_targets, select_from_classes\n",
    "from utils.visualization import show_imgs, get_model_dot, LivePlot\n",
    "from utils.others import measure_alloc_mem, count_parameters\n",
    "from utils.timing import func_timer\n",
    "from utils.metrics import get_accuracy\n",
    "\n",
    "import wandb\n",
    "from IPython.display import clear_output\n",
    "import tqdm\n",
    "from livelossplot import PlotLosses\n",
    "import lovely_tensors as lt\n",
    "\n",
    "lt.monkey_patch()\n",
    "torch.set_printoptions(precision=3, linewidth=180)\n",
    "%env \"WANDB_NOTEBOOK_NAME\" \"main.ipynb\"\n",
    "wandb.login()\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"batch_size\": 18,\n",
    "    \"seq_len\": 40,\n",
    "    \"num_of_tasks\": 2**8,\n",
    "    \"permuted_labels_frac\": 0.1,\n",
    "    \"whole_seq_prediction\": True,\n",
    "    \"lr\": 3e-4,\n",
    "    \"eps\": 1e-16,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "}\n",
    "\n",
    "print(f\"... Running on {config['device']} ...\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tasks(num_of_tasks):\n",
    "    # proj_matrices = torch.randn(num_of_tasks, 1, 784, 784)\n",
    "    proj_matrices = torch.distributions.Normal(0, 1/784).sample((num_of_tasks, 1, 784, 784))\n",
    "    proj_matrices /= torch.norm(proj_matrices, dim=(2, 3), keepdim=True)\n",
    "    label_perms = torch.cat([torch.randperm(10).unsqueeze(0) for _ in range(num_of_tasks)], dim=0)\n",
    "    return proj_matrices, label_perms\n",
    "\n",
    "proj_matrices, label_perms = create_tasks(num_of_tasks=config[\"num_of_tasks\"])\n",
    "proj_matrices, label_perms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_seqs(X, y, proj_matrices=None, label_perms=None, seq_len=32, labels_shifted_by_one=False):\n",
    "    # flatten the images + split into sequences\n",
    "    _X = X.view(X.shape[0] // seq_len, seq_len, 1, -1) # (batch_size, seq_len, 1, 784)\n",
    "    \n",
    "    # apply projection matrices\n",
    "    if proj_matrices is not None:\n",
    "        _X = _X @ proj_matrices.transpose(-1, -2)\n",
    "        # rescale the projected image values (needed?)\n",
    "        _X = (_X - _X.min()) / (_X.max() - _X.min())\n",
    "\n",
    "    _y = y.view(y.shape[0] // seq_len, seq_len) # (batch_size, seq_len)\n",
    "    # apply label permutations\n",
    "    if label_perms is not None:\n",
    "        _y = torch.gather(label_perms, dim=1, index=_y)\n",
    "\n",
    "    if labels_shifted_by_one:\n",
    "        seqs_y = _y.clone() # target labels\n",
    "        # append labels to images - labels shifted by one to the right\n",
    "        _y = F.one_hot(_y[:, :-1])\n",
    "        _y = torch.cat([torch.zeros(size=(_y.shape[0], 1, _y.shape[-1]), device=_y.device), _y], dim=1)\n",
    "        _X = torch.concat((_X.squeeze(2), _y), dim=-1)\n",
    "    else:\n",
    "        # get the target label for each sequence (last label in the sequence)\n",
    "        seqs_y = _y[:, -1]\n",
    "        # append labels to images ((x1,y1), (x2,y2), ..., (xn-1, yn-1), (xn, 0)) - all except the last one\n",
    "        _y = F.one_hot(_y)\n",
    "        _y[:, -1, :] = 0 # remove the last label from the sequence (to be predicted)\n",
    "        _X = torch.concat((_X.squeeze(2), _y), dim=-1)\n",
    "\n",
    "    return _X, seqs_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader, classes = get_mnist_data_loaders(\n",
    "    batch_size=config[\"batch_size\"] * config[\"seq_len\"], flatten=False, only_classes=None, img_size=28\n",
    ")\n",
    "\n",
    "# show sample images\n",
    "X, y = next(iter(train_loader))\n",
    "X_rand, y_rand = get_context_seqs(X, y, proj_matrices=proj_matrices[:config[\"batch_size\"]], label_perms=label_perms[:config[\"batch_size\"]],\n",
    "    seq_len=config[\"seq_len\"], labels_shifted_by_one=False)\n",
    "\n",
    "show_imgs(\n",
    "    imgs=torch.cat([X[-5:], X_rand[-1,-5:,:784].view(-1, 1, 28, 28)], dim=0),\n",
    "    titles=torch.cat([y[-5:], X_rand[-1,-5:-1,784:].argmax(-1), y_rand[-1].unsqueeze(0)], dim=0).tolist()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        heads=2,\n",
    "        dim_head=16,\n",
    "        dropout=0.,\n",
    "        causal=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        self.heads = heads\n",
    "        self.causal = causal\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
    "        self.to_out = nn.Linear(inner_dim, dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        q, k, v = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        q, k, v = map(lambda t: rearrange(t, \"b n (h d) -> b h n d\", h=self.heads), (q, k, v))\n",
    "        sim = einsum(\"b h i d, b h j d -> b h i j\", q, k) * self.scale\n",
    "\n",
    "        if self.causal:\n",
    "            # apply causal mask\n",
    "            mask = torch.ones(size=sim.shape[-2:], device=sim.device).triu_(1).bool()\n",
    "            sim.masked_fill_(mask, float(\"-inf\"))\n",
    "\n",
    "        attn = sim.softmax(dim=-1) # (batch, heads, query, key)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = einsum(\"b h i j, b h j d -> b h i d\", attn, v)\n",
    "        out = rearrange(out, \"b h n d -> b n (h d)\", h=self.heads) # merge heads\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        depth,\n",
    "        heads,\n",
    "        dim_head,\n",
    "        token_dim=784 + 10,\n",
    "        inner_dim=None,\n",
    "        dropout=0.,\n",
    "        causal=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed_proj = nn.Linear(token_dim, dim)\n",
    "        self.layers = nn.ModuleList([])\n",
    "        inner_dim = inner_dim or 4 * dim\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout, causal=causal),\n",
    "                nn.LayerNorm(dim),\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(dim, inner_dim),\n",
    "                    nn.GELU(),\n",
    "                    nn.Linear(inner_dim, dim),\n",
    "                    nn.Dropout(dropout)\n",
    "                ),\n",
    "                nn.LayerNorm(dim)\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed_proj(x)\n",
    "        for attn, ln1, mlp, ln2 in self.layers:\n",
    "            x = x + attn(x)\n",
    "            x = x + mlp(ln1(x))\n",
    "        return x\n",
    "\n",
    "class InContextLearner(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        depth=2,\n",
    "        heads=4,\n",
    "        dim_head=16,\n",
    "        inner_dim=None,\n",
    "        dropout=0.1,\n",
    "        whole_seq_prediction=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        inner_dim = inner_dim or 4 * dim\n",
    "        self.whole_seq_prediction = whole_seq_prediction\n",
    "        self.transformer = Transformer(\n",
    "            dim=dim,\n",
    "            depth=depth,\n",
    "            heads=heads,\n",
    "            dim_head=dim_head,\n",
    "            inner_dim=inner_dim,\n",
    "            dropout=dropout,\n",
    "            causal=whole_seq_prediction,\n",
    "        )\n",
    "        self.final_classifier = nn.Linear(dim, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer(x) # (batch, seq_len, dim)\n",
    "        if self.whole_seq_prediction:\n",
    "            return self.final_classifier(x)\n",
    "        else:\n",
    "            return self.final_classifier(x[:,-1,:])\n",
    "\n",
    "# model_dim = 28 * 28 + 10\n",
    "model_dim = 256\n",
    "model = InContextLearner(\n",
    "    dim=model_dim,\n",
    "    depth=4,\n",
    "    heads=6,\n",
    "    dim_head=32,\n",
    "    inner_dim=4 * model_dim,\n",
    "    dropout=0.1,\n",
    "    whole_seq_prediction=config[\"whole_seq_prediction\"]\n",
    ").to(config[\"device\"])\n",
    "print(model)\n",
    "print(f\"{count_parameters(model)} trainable parameters\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval model\n",
    "def eval(model, test_loader, apply_proj=False):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss, acc, acc_max_improvement_within_seq = 0, 0, 0\n",
    "        acc_over_seq = np.array([0.] * config[\"seq_len\"])\n",
    "        for X, y in test_loader:\n",
    "            X, y = X.to(config[\"device\"]), y.to(config[\"device\"])\n",
    "\n",
    "            curr_proj_matrices, curr_label_perms = None, None\n",
    "            if apply_proj:\n",
    "                # randomly sample tasks (one task for each sequence/context)\n",
    "                task_idxs = np.random.randint(0, config[\"num_of_tasks\"], size=config[\"batch_size\"])\n",
    "                curr_proj_matrices, curr_label_perms = proj_matrices[task_idxs].to(config[\"device\"]), label_perms[task_idxs].to(config[\"device\"])\n",
    "            X, y = get_context_seqs(X, y, proj_matrices=curr_proj_matrices, label_perms=curr_label_perms,\n",
    "                seq_len=config[\"seq_len\"], labels_shifted_by_one=config[\"whole_seq_prediction\"]) # (batch, seq_len, dim)\n",
    "\n",
    "            y_hat = model(X)\n",
    "            if config[\"whole_seq_prediction\"]:\n",
    "                loss += F.cross_entropy(y_hat.view(-1, 10), y.view(-1)).item()\n",
    "                acc_over_seq += (y_hat.argmax(dim=-1) == y).float().mean(dim=0).cpu().numpy() # (seq_len,)\n",
    "                acc_max_improvement_within_seq += \\\n",
    "                    ((y_hat[:,1:,:].argmax(dim=-1) == y[:,1:]).float().max(dim=-1).values \\\n",
    "                    - (y_hat[:,0,:].argmax(dim=-1) == y[:,0]).float()).mean().item()\n",
    "            else:\n",
    "                loss += F.cross_entropy(y_hat, y).item()\n",
    "            acc += (y_hat.argmax(dim=-1) == y).float().mean().item()\n",
    "        loss /= len(test_loader)\n",
    "        acc /= len(test_loader)\n",
    "        acc_over_seq = list(acc_over_seq / len(test_loader))\n",
    "        acc_max_improvement_within_seq /= len(test_loader)\n",
    "        print(f\"loss: {loss:.4f}, acc: {acc:.4f}\")\n",
    "    return loss, acc, acc_over_seq, acc_max_improvement_within_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optim = torch.optim.Adam(model.parameters(), lr=config[\"lr\"], eps=config[\"eps\"])\n",
    "\n",
    "# logging\n",
    "groups = [\"train_loss\", \"train_acc\", \"eval_loss\", \"eval_acc\"]\n",
    "if config[\"whole_seq_prediction\"]:\n",
    "    groups.extend([\"train_acc_over_seq\", \"train_acc_max_improvement_within_seq\", \"eval_acc_over_seq\", \"eval_acc_max_improvement_within_seq\"])\n",
    "live_plot = LivePlot(figsize=(26, 24) if config[\"whole_seq_prediction\"] else (26, 14), use_seaborn=False, groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proj_matrices, label_perms = proj_matrices.to(config[\"device\"]), label_perms.to(config[\"device\"]) # save gpu mem\n",
    "\n",
    "for epoch in tqdm.tqdm(range(200)):\n",
    "    model.train()\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        X, y = X.to(config[\"device\"]), y.to(config[\"device\"])\n",
    "        \n",
    "        # randomly sample tasks (one task for each sequence/context)\n",
    "        task_idxs = np.random.randint(0, config[\"num_of_tasks\"], size=config[\"batch_size\"])\n",
    "        curr_proj_matrices, curr_label_perms = proj_matrices[task_idxs].to(config[\"device\"]), label_perms[task_idxs].to(config[\"device\"])\n",
    "        curr_label_perms[int(config[\"permuted_labels_frac\"] * config[\"batch_size\"]):] = torch.tensor(np.arange(10)).to(config[\"device\"]) # no permutation for some of the sequences\n",
    "        X, y = get_context_seqs(X, y, proj_matrices=curr_proj_matrices, label_perms=curr_label_perms,\n",
    "            seq_len=config[\"seq_len\"], labels_shifted_by_one=config[\"whole_seq_prediction\"]) # (batch, seq_len, dim)\n",
    "\n",
    "        y_hat = model(X)\n",
    "        if config[\"whole_seq_prediction\"]:\n",
    "            loss = F.cross_entropy(y_hat.view(-1, 10), y.view(-1))\n",
    "        else:\n",
    "            loss = F.cross_entropy(y_hat, y)\n",
    "        loss.backward()\n",
    "        model_optim.step()\n",
    "        model_optim.zero_grad()\n",
    "\n",
    "        # update the plot\n",
    "        if i % 20 == 19:\n",
    "            if config[\"whole_seq_prediction\"]:\n",
    "                acc_over_seq = (y_hat.argmax(dim=-1) == y).float().mean(dim=0) # (seq_len,)\n",
    "                acc_max_improvement_within_seq = \\\n",
    "                    ((y_hat[:,1:,:].argmax(dim=-1) == y[:,1:]).float().max(dim=-1).values \\\n",
    "                    - (y_hat[:,0,:].argmax(dim=-1) == y[:,0]).float()).mean().item()\n",
    "                live_plot.update({\"train_acc_over_seq\": acc_over_seq.tolist()}, reset=True)\n",
    "                live_plot.update({\"train_acc_max_improvement_within_seq\": acc_max_improvement_within_seq})\n",
    "            live_plot.update({\"train_loss\": loss.item(), \"train_acc\": (y_hat.argmax(dim=-1) == y).float().mean().item()})\n",
    "            live_plot.draw()\n",
    "    #     break\n",
    "    loss, acc, acc_over_seq, acc_max_improvement_within_seq = eval(model, test_loader, apply_proj=False)\n",
    "    live_plot.update({\"eval_loss\": loss, \"eval_acc\": acc})\n",
    "    if config[\"whole_seq_prediction\"]:\n",
    "        live_plot.update({\"eval_acc_max_improvement_within_seq\": acc_max_improvement_within_seq})\n",
    "        live_plot.update({\"eval_acc_over_seq\": acc_over_seq}, reset=True)\n",
    "    live_plot.draw()\n",
    "    # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5692ede66a2eeda96ca4e496ad881a063b66ee8e9ec6003b28974c60439bc6fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
